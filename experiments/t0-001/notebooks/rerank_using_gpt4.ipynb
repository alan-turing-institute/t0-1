{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53225c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "filename= \"../data/evaluation/evaluation_vector_store_results_2025-04-26_12-03-28.jsonl\" #k=30\n",
    "#filename = \"../data/evaluation/evaluation_vector_store_results_2025-04-26_12-11-06.jsonl\" #k=50\n",
    "with open(filename, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    data = [json.loads(line) for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "154272b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['general_demographics', 'symptoms_description', 'query_type', 'severity_level', 'conditions_title', 'query_field', 'target_document_field', 'k', 'retrieved_documents', 'retrieved_documents_scores', 'retrieved_documents_sources', 'match'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a48bfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retriever performance: 0.88\n",
      "Retriever performance for downplay: 0.8425925925925926\n",
      "Retriever performance for basic: 0.8571428571428571\n",
      "Retriever performance for hypochondriac: 0.9350282485875706\n"
     ]
    }
   ],
   "source": [
    "#retriever_performance = sum([x[\"match\"] for x in data])/len(data)\n",
    "retriever_performance = sum([x[\"match\"] for x in data])/len(data)\n",
    "print(f\"Retriever performance: {retriever_performance}\")\n",
    "\n",
    "query_types = set([x[\"query_type\"] for x in data])\n",
    "for query_type in query_types:\n",
    "    query_type_data = [x for x in data if x[\"query_type\"] == query_type]\n",
    "    retriever_performance = sum([x[\"match\"] for x in query_type_data])/len(query_type_data)\n",
    "    print(f\"Retriever performance for {query_type}: {retriever_performance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da126efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Specify the path to your .env file\n",
    "dotenv_path = Path(\"../.env\")\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "def get_env_var(key: str) -> str:\n",
    "    try:\n",
    "        return os.environ[key]\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Please set the {key} environment variable.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54d480b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(symptoms_description, document_titles, document_text, k):\n",
    "    prompt = f\"\"\"\n",
    "    You are part of a retrieval system for a medical domain.\n",
    "    Given a description of symptoms provided by a patient, an initial retriever has shortlisted several possible conditions, along with their distance scores (so lower is better) and the associated document content.\n",
    "    \n",
    "    Here is the patient's symptom description:\n",
    "    {symptoms_description}\n",
    "    \n",
    "    The shortlisted conditions and their retrieval scores are:\n",
    "    {document_titles}\n",
    "    \n",
    "    The corresponding condition descriptions are:\n",
    "    {document_text}\n",
    "    \n",
    "    Your task is to select the {k} most likely conditions based on the symptoms. \n",
    "    Please return only the titles of the selected conditions, comma-separated.\n",
    "    \"\"\"\n",
    "    return prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7139220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "\n",
    "# basic function to prompt the model\n",
    "def get_response_from_ollama(prompt, model=\"gemma3:1b\"):\n",
    "    response = ollama.generate(model=model, prompt=prompt)\n",
    "    return response[\"response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699b99d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_TOKENS = 2048\n",
    "AZURE_OPENAI_API_VERSION = \"2024-12-01-preview\"\n",
    "\n",
    "model = \"gpt-4o\"\n",
    "\n",
    "endpoint = get_env_var(\"AZURE_OPENAI_ENDPOINT_gpt-4o\")\n",
    "key = get_env_var(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "client = AzureOpenAI(\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        azure_endpoint=endpoint,\n",
    "        api_key=key,\n",
    "        )\n",
    "\n",
    "def get_response (prompt: str, model: str) -> str:\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        max_completion_tokens=MAX_TOKENS,\n",
    "        model=model,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c7428a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/nhs-conditions/v3/conditions.jsonl\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "conditions = {}\n",
    "for line in lines:\n",
    "    condition = json.loads(line)\n",
    "    conditions[condition[\"condition_title\"]] = condition['condition_content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a0fa4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def re_rank_documents(line, k):\n",
    "    symptoms_description = line['symptoms_description']\n",
    "    #document_titles = line['retrieved_documents_sources']\n",
    "    document_titles = [(source, score) for source, score in zip(line[\"retrieved_documents_sources\"], line[\"retrieved_documents_scores\"])]\n",
    "\n",
    "    best_sources = {}\n",
    "\n",
    "    for source, score in document_titles:\n",
    "        if source not in best_sources or score < best_sources[source]:\n",
    "            best_sources[source] = score\n",
    "\n",
    "    document_titles_unique = sorted(best_sources.items(), key=lambda x: x[1])\n",
    "\n",
    "    document_text = \"\\n\\n\".join([conditions[title] for title, score in document_titles_unique])\n",
    "\n",
    "    #document_text =\"\"\n",
    "    prompt = make_prompt(symptoms_description, document_titles_unique, document_text, k=k)\n",
    "    response = get_response(prompt, model)\n",
    "    #response = get_response_from_ollama(prompt, model=\"gemma3:4b\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becd3f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [03:37<1:29:27,  5.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 101/1000 [07:06<56:15,  3.76s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.84\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [10:25<49:41,  3.52s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.8333333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 204/1000 [13:50<44:17,  3.34s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 254/1000 [17:23<42:04,  3.38s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 304/1000 [21:00<1:03:16,  5.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.8033333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 355/1000 [24:14<39:37,  3.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.8028571428571428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 405/1000 [27:34<32:35,  3.29s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 455/1000 [31:04<50:33,  5.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7888888888888889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 505/1000 [34:13<18:08,  2.20s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 555/1000 [37:32<22:20,  3.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7872727272727272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 607/1000 [40:24<17:08,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7883333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 657/1000 [43:35<21:32,  3.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7861538461538462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 708/1000 [47:08<16:24,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7785714285714286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 758/1000 [50:24<16:44,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7786666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 808/1000 [53:55<13:19,  4.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 858/1000 [57:29<11:46,  4.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7847058823529411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 908/1000 [1:00:35<04:50,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7833333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 958/1000 [1:04:09<02:50,  4.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Current accuracy: 0.7863157894736842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [1:06:42<00:00,  4.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5, Reranking accuracy: 0.782258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 51/1000 [03:53<1:12:12,  4.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 102/1000 [06:58<44:31,  2.97s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 152/1000 [10:09<43:53,  3.11s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.78\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 203/1000 [13:45<1:07:03,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 253/1000 [17:08<36:04,  2.90s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 304/1000 [20:47<1:01:40,  5.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.7433333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 354/1000 [24:02<30:20,  2.82s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.7428571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 404/1000 [27:07<31:18,  3.15s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.73\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 454/1000 [30:14<38:42,  4.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=3, Current accuracy: 0.7333333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 468/1000 [31:25<40:24,  4.56s/it]"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "cutoff = 1000\n",
    "\n",
    "for k in [5,3]:\n",
    "    ct = 0\n",
    "    tot = 0\n",
    "    for line in tqdm.tqdm(data[:cutoff]):\n",
    "        try:\n",
    "            reranked_documents = re_rank_documents(line, k).split(\",\")\n",
    "            reranked_documents = [x.strip().replace('\"',\"\").replace(\"'\",\"\").replace(\" \",\"-\").lower() for x in reranked_documents]\n",
    "            gold_document = line['conditions_title']\n",
    "            tot += 1\n",
    "            if gold_document in reranked_documents:\n",
    "                ct += 1\n",
    "            if tot % 50 == 0:\n",
    "                print (f\"k={k}, Current accuracy: {ct/tot}\")\n",
    "        except Exception as e:\n",
    "            #print (f\"Error: {e}\")\n",
    "            continue\n",
    "    print (f\"k={k}, Reranking accuracy: {ct/tot}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary k=50\n",
    "# k=3 accuracy=\n",
    "# k=5 accuracy=\n",
    "\n",
    "### Summary k=30\n",
    "# k=3 accuracy=\n",
    "# k=5 accuracy=0.78\n",
    " \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
