# Sprint 1 Plan (weeks 1 and 2)

This plan is current as of 31 March 2025.

Our dataset consists of the contents of the approximately 1,000
websites at nhs.uk/conditions. Each page, which is labelled by a
condition, contains:
- symptoms;
- an explanation of the condition and treatment options;
- recommendations for next steps (eg "Call 999 if ...").

The goal of sprint 1 is to develop a small number of _tasks_ for a
knowledge retrieval use-case using this corpus; and to evaluate one or
more (RAG) models on those tasks.

## Main task

We want to approximate a user-query, corresponding to descriptions of
the sympoms of an imaginary patient. In the following task, the model
is to predict one or more conditions corresponding to a set of
symptoms.

1. Task T001. Preduct condition from a description of symptoms (“the
   complaint”). To create the complaint, we
   1. Randomly select a condition.
   2. Ask a large model (via API) to generate a synthetic complaint as
      if from a patient suffering from that condition. The large model
      will be provided with the NHS web page for that condition as
      part of its prompt.

(See later for other tasks, if time allows.)

## TODOs

- Extract text from website for each condition. (NB: Some sub-folder
  conditions are missing! Eg, under `liver-cancer`.)
- Stand up a vector database on VM.
- Create an embedding for each website and store in the vector
  database.
- Set up infrastructure for generating API requests to a large LLM on
  Azure.
- Create synthetic patient complaints for task T001
- Set up infrastructure to evaluate precision on task T001
- Evaluate just vector-database lookup on T001
- Evaluate RAG on T001:
  - Using large online model (via API);
  - Using stock “small,” model (locally, on server);
- Fine-tune stock model
- Evaluate RAG on T001 using fine-tuned model.
- Repeat as time allows for T002 onwards.


## Other tasks

The following are as time allows

2. Task T002. Experiment with prompting the large model to suppose it
   is a hypochondriac, or otherwise has a confusing mix of
   symptoms. (We may have to ask it to add symptoms from its own
   “knoweldge.”)

3. Task T003. As task T001 except we provide the large model with
   multiple conditions and ask it to imagine it is suffering from all
   of these.

4. Task T004. We ask the large model to generate an incomplete
   complaint. Our model is prompted to ask for more (pertinent)
   symptoms and then to guess as in T001.

In all of these the model is to produce one or more conditions as
output, and we will record the overall precision. (Or "precision at
k", where k is the number of conditions suggested.)

5. Task T005. We ask the model to predict, not the condition, but the
   recommended next action.

Task T005 is likely evaluated using another large model to score the answer.
