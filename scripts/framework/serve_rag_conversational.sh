#!/bin/sh
t0-1 serve-rag \
     --k 5 \
     --db-choice chroma \
     --conditions-file ./data/nhs-conditions/conditions.jsonl \
     --llm-provider openai_completion \
     --llm-model-name /data/t0-rcp/llama.cpp/t0-2.5-gemma-3-4B-it-F16.gguf \
     --budget-forcing \
     --budget-forcing-kwargs '{"max_tokens_thinking": 512, "num_stop_skips": 0}' \
     --budget-forcing-tokenizer Qwen/Qwen3-4B-Instruct-2507 \
     --extra-body '{"max_tokens": 4096, "seed": 42}' \
     --conversational \
     --conversational-agent-llm-provider openai \
     --conversational-agent-llm-model-name /data/t0-rcp/llama.cpp/unsloth_gpt-oss-20b-GGUF_gpt-oss-20b-Q8_0.gguf \
     --conversational-agent-extra-body '{"max_tokens": 4096, "seed": 42}' \
     --prompt-template-path ./templates/rag_prompt_conversational.txt \
     --system-prompt-path ./templates/rag_system_prompt_conversational.txt \
     --persist-directory ./v4-summarised-db \
     --local-file-store ./v4-summarised-lfs \
     --host 0.0.0.0 \
     --port 8050 \
     --seed 42
