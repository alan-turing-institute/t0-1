"""
Script to convert Qwen-formatted training data to Gemma format.

Transforms the 'text' field from Qwen's chat template tokens to Gemma's format:
- Qwen: <|im_start|>, <|im_end|> tokens with system/user/assistant/think/answer roles
- Gemma: <start_of_turn>, <end_of_turn> tokens with user/model roles

The thinking structure is preserved as inline formatted text:
[Thinking: ...] and [Answer: ...] within the model's response.

Usage:
    python convert_to_gemma_format.py <input_path> [output_path]

    If output_path is not provided, it will be generated by adding '_gemma' suffix
    to the input path.
"""

import re
import sys
import argparse
from datasets import load_from_disk
from pathlib import Path


def parse_qwen_text(text: str) -> dict:
    """
    Parse Qwen-formatted text into structured components.

    Returns:
        dict with keys: 'system', 'user', 'thinking', 'answer'
    """
    components = {}

    # Extract system message
    system_match = re.search(r'<\|im_start\|>system\n(.*?)<\|im_end\|>', text, re.DOTALL)
    if system_match:
        components['system'] = system_match.group(1).strip()
    else:
        components['system'] = ""

    # Extract user message
    user_match = re.search(r'<\|im_start\|>user\n(.*?)<\|im_end\|>', text, re.DOTALL)
    if user_match:
        components['user'] = user_match.group(1).strip()
    else:
        components['user'] = ""

    # Extract thinking section
    thinking_match = re.search(r'<\|im_start\|>think\n(.*?)(?=<\|im_start\|>answer|$)', text, re.DOTALL)
    if thinking_match:
        components['thinking'] = thinking_match.group(1).strip()
    else:
        components['thinking'] = ""

    # Extract answer section
    answer_match = re.search(r'<\|im_start\|>answer\n(.*?)<\|im_end\|>', text, re.DOTALL)
    if answer_match:
        components['answer'] = answer_match.group(1).strip()
    else:
        components['answer'] = ""

    return components


def convert_to_gemma_format(components: dict) -> str:
    """
    Convert parsed components to Gemma chat template format.

    Gemma format:
    <bos><start_of_turn>user
    [System message prepended if present]

    [User message]<end_of_turn>
    <start_of_turn>model
    [Thinking: ...]

    [Answer: ...]<end_of_turn>
    """
    # Build user turn (system message prepended to user message)
    user_content = []
    if components['system']:
        user_content.append(components['system'])
    if components['user']:
        user_content.append(components['user'])

    user_turn = '\n\n'.join(user_content)

    # Build model turn (thinking + answer as inline formatted text)
    model_content = []
    if components['thinking']:
        model_content.append(f"[Thinking: {components['thinking']}]")
    if components['answer']:
        model_content.append(f"[Answer: {components['answer']}]")

    model_turn = '\n\n'.join(model_content)

    # Assemble complete Gemma format
    gemma_text = (
        f"<bos><start_of_turn>user\n"
        f"{user_turn}<end_of_turn>\n"
        f"<start_of_turn>model\n"
        f"{model_turn}<end_of_turn>"
    )

    return gemma_text


def transform_dataset(input_path: str, output_path: str):
    """
    Transform entire dataset from Qwen to Gemma format.

    Args:
        input_path: Path to input dataset (Qwen format)
        output_path: Path to save transformed dataset (Gemma format)
    """
    print(f"Loading dataset from: {input_path}")
    dataset = load_from_disk(input_path)

    print(f"Dataset loaded: {dataset}")
    print(f"Number of training samples: {len(dataset['train'])}")

    def transform_example(example):
        """Transform a single example's text field."""
        components = parse_qwen_text(example['text'])
        example['text'] = convert_to_gemma_format(components)
        return example

    print("\nTransforming dataset...")
    transformed_dataset = dataset.map(transform_example)

    print(f"\nSaving transformed dataset to: {output_path}")
    transformed_dataset.save_to_disk(output_path)

    print("Transformation complete!")

    # Print first example for manual verification
    print("\n" + "="*80)
    print("FIRST EXAMPLE - ORIGINAL (Qwen format):")
    print("="*80)
    print(dataset['train'][0]['text'][:1000])
    print("...")

    print("\n" + "="*80)
    print("FIRST EXAMPLE - TRANSFORMED (Gemma format):")
    print("="*80)
    print(transformed_dataset['train'][0]['text'][:1000])
    print("...")

    return transformed_dataset


def main():
    """Main function to handle CLI arguments and run conversion."""
    parser = argparse.ArgumentParser(
        description="Convert Qwen-formatted training data to Gemma format"
    )
    parser.add_argument(
        "input_path",
        type=str,
        help="Path to input dataset (Qwen format)"
    )
    parser.add_argument(
        "output_path",
        type=str,
        nargs='?',
        default=None,
        help="Path to save transformed dataset (Gemma format). "
             "If not provided, adds '_gemma' suffix to input path."
    )
    parser.add_argument(
        "-f", "--force",
        action="store_true",
        help="Overwrite output without prompting if it exists"
    )

    args = parser.parse_args()

    input_path = args.input_path

    # Generate output path if not provided
    if args.output_path is None:
        output_path = f"{input_path}_gemma"
    else:
        output_path = args.output_path

    # Check if input exists
    if not Path(input_path).exists():
        print(f"Error: Input dataset not found: {input_path}", file=sys.stderr)
        sys.exit(1)

    # Check if output already exists
    if Path(output_path).exists() and not args.force:
        response = input(f"\nOutput path '{output_path}' already exists. Overwrite? (yes/no): ")
        if response.lower() != 'yes':
            print("Transformation cancelled.")
            sys.exit(0)

    transformed_dataset = transform_dataset(input_path, output_path)

    print(f"\n✓ Successfully transformed {len(transformed_dataset['train'])} samples")
    print(f"✓ Saved to: {output_path}")


if __name__ == "__main__":
    main()
